{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG_BiLSTM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moustafa-7/ECG-web-app/blob/master/ECG_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkUosn_Z4t9E",
        "colab_type": "code",
        "outputId": "1d820b60-93ae-4587-c3a7-704fb9e64a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T1eiSxn3WlM",
        "colab_type": "code",
        "outputId": "fe1a88b8-2e86-49ae-fc3b-5f1fc729c06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install wfdb\n",
        "!pip install pywavelets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/96/c2200539fdf4f087e14d30ed62a66544b6f441196bcb8ecc7a29ec6503b9/wfdb-2.2.1.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.1MB/s \n",
            "\u001b[?25hCollecting nose>=1.3.7 (from wfdb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.16.5)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.0.3)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.21.0)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.3.1)\n",
            "Requirement already satisfied: sklearn>=0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.5.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->wfdb) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn>=0.0->wfdb) (0.21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.5.1->wfdb) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.1->wfdb) (41.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn>=0.0->wfdb) (0.13.2)\n",
            "Building wheels for collected packages: wfdb\n",
            "  Building wheel for wfdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wfdb: filename=wfdb-2.2.1-cp36-none-any.whl size=100368 sha256=c34298bc460089e36030304af187c0c2cd6b238d0098dc75fd8434953a4acdd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a9/00/0078d26b0c15b31be0001af8eb659496709c361c69641303f1\n",
            "Successfully built wfdb\n",
            "Installing collected packages: nose, wfdb\n",
            "Successfully installed nose-1.3.7 wfdb-2.2.1\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from pywavelets) (1.16.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7v9TK4n4IcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys, os\n",
        "import wfdb\n",
        "import pywt\n",
        "import pickle as pk\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDakp6K24P9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_names = ['100', '101', '102', '103', '104', '105', '106', '107', \n",
        "              '108', '109', '111', '112', '113', '114', '115', '116', \n",
        "              '117', '118', '119', '121', '122', '123', '124', '200', \n",
        "              '201', '202', '203', '205', '207', '208', '209', '210', \n",
        "              '212', '213', '214', '215', '217', '219', '220', '221', \n",
        "              '222', '223', '228', '230', '231', '232', '233', '234']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E6aS5hk4Rdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wid = 100\n",
        "\n",
        "labels =  \n",
        "X = []\n",
        "Y = []\n",
        "for d in data_names:\n",
        "  r=wfdb.rdrecord('drive/My Drive/ECG_project/files/mitdb/1.0.0/'+d)\n",
        "  ann=wfdb.rdann('drive/My Drive/ECG_project/files/mitdb/1.0.0/'+d, 'atr', return_label_elements=['label_store', 'symbol'])\n",
        "  sig = np.array(r.p_signal[:,0])\n",
        "  sig_len = len(sig)\n",
        "  sym = ann.symbol\n",
        "  pos = ann.sample\n",
        "  beat_len = len(sym)\n",
        "  for i in range(1,beat_len-1):\n",
        "    if sym[i] in labels: \n",
        "      if (pos[i]-pos[i-1])>200 and (pos[i+1]-pos[i])>200:\n",
        "        a = sig[pos[i]-150:pos[i]+150]\n",
        "        a, cD3, cD2, cD1 = pywt.wavedec(a, 'db6', level=3)\n",
        "        X.append(a)\n",
        "        Y.append(labels.index(sym[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-i5VE2e4WKD",
        "colab_type": "code",
        "outputId": "b5284a53-24e5-4c60-985c-377f8d85e9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(Counter(Y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78546, 47)\n",
            "(78546,)\n",
            "Counter({0: 60621, 1: 7772, 2: 7141, 3: 1585, 4: 1427})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOkTOhut6Db6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_len = len(X)\n",
        "np.random.seed(42)\n",
        "idx = list(range(data_len))\n",
        "np.random.shuffle(idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoCVRMiV6Qn4",
        "colab_type": "code",
        "outputId": "937ebd99-005c-46a0-f563-e6013fe01619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_len = int(data_len*0.8) #\n",
        "valid_len = int(data_len*0.2)\n",
        "\n",
        "X_train = X[idx][:train_len]\n",
        "X_valid = X[idx][train_len:train_len+valid_len]\n",
        "Y_train = Y[idx][:train_len]\n",
        "Y_valid = Y[idx][train_len:train_len+valid_len]\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(Counter(Y_train))\n",
        "print(Counter(Y_valid))\n",
        "\n",
        "fn = \"data_\"+\"NLRAV\"+\".pk\"\n",
        "with open(fn, \"wb\") as fw:\n",
        "    pk.dump(X_train, fw, protocol=pk.HIGHEST_PROTOCOL)\n",
        "    pk.dump(Y_train, fw, protocol=pk.HIGHEST_PROTOCOL)\n",
        "    pk.dump(X_valid, fw, protocol=pk.HIGHEST_PROTOCOL)\n",
        "    pk.dump(Y_valid, fw, protocol=pk.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(62836, 47)\n",
            "(15709, 47)\n",
            "Counter({0: 48390, 1: 6280, 2: 5744, 3: 1280, 4: 1142})\n",
            "Counter({0: 12231, 1: 1491, 2: 1397, 3: 305, 4: 285})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EmJGHG47CZu",
        "colab_type": "code",
        "outputId": "50f5fbe1-77b6-43da-c569-58152c56dcf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle as pk\n",
        "import os, sys\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def get_session(gpu_fraction=0.1):\n",
        "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
        "    return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "  \n",
        "K.set_session(get_session())\n",
        "\n",
        "\n",
        "\n",
        "mode = \"NLRAV\" # NLRAV / NSVFQ\n",
        "model_type = \"BiLSTM\"\n",
        "save = \"result_NLRAV_0_1\" # result_NLRAV_0\n",
        "\n",
        "fn = \"data_\"+mode+\".pk\"\n",
        "with open(fn, \"rb\") as fp:\n",
        "    X_train = pk.load(fp)\n",
        "    Y_train = pk.load(fp)\n",
        "    X_valid = pk.load(fp)\n",
        "    Y_valid = pk.load(fp)\n",
        "    \n",
        "\n",
        "if model_type != 'Dense':\n",
        "    X_train = np.expand_dims(X_train, axis=-1)\n",
        "    X_valid = np.expand_dims(X_valid, axis=-1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "f_size = X_train.shape[1]\n",
        "class_num = 5\n",
        "\n",
        "#============================================#\n",
        "\n",
        "lr = 0.005\n",
        "batch_size=128\n",
        "\n",
        "Y_train = keras.utils.to_categorical(Y_train, num_classes=class_num)\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    if model_type == '1D':\n",
        "        model.add(Conv1D(18, 7, activation='relu', input_shape=(f_size,1)))\n",
        "        model.add(MaxPooling1D(2))\n",
        "        model.add(Conv1D(18, 7, activation='relu'))\n",
        "        model.add(MaxPooling1D(2))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(100, activation='relu'))\n",
        "    elif model_type == '1D-small':\n",
        "        model.add(Conv1D(10, 3, activation='relu', input_shape=(f_size,1)))\n",
        "        model.add(MaxPooling1D(2))\n",
        "        model.add(Conv1D(10, 3, activation='relu'))\n",
        "        model.add(MaxPooling1D(2))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(100, activation='relu'))\n",
        "    elif model_type == '1D-large':\n",
        "        model.add(Conv1D(50, 13, activation='relu', input_shape=(f_size,1)))\n",
        "        model.add(MaxPooling1D(2))\n",
        "        model.add(Conv1D(50, 13, activation='relu'))\n",
        "        model.add(MaxPooling1D(2))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(100, activation='relu'))\n",
        "    elif model_type == 'LSTM':\n",
        "        model.add(LSTM(64, return_sequences=True, dropout=0.1, input_shape=(f_size, 1)))\n",
        "        model.add(LSTM(32, return_sequences=True, dropout=0.1))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "    elif model_type == 'BiLSTM':\n",
        "        model.add(Bidirectional(LSTM(64, return_sequences=True, dropout=0.1), merge_mode='sum', input_shape=(f_size, 1)))\n",
        "        model.add(Bidirectional(LSTM(32, return_sequences=True, dropout=0.1), merge_mode='sum'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "    elif model_type == 'Dense':\n",
        "        model.add(Dense(256, input_dim=f_size, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(256, input_dim=f_size, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "    model.add(Dense(class_num, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr))\n",
        "    return model\n",
        "\n",
        "model = make_model()\n",
        "best_SE = 0\n",
        "best_ACC = 0\n",
        "best_model = make_model()\n",
        "patience = 30\n",
        "pcnt = 0\n",
        "\n",
        "bin_label = lambda x: min(1,x)\n",
        "\n",
        "for e in range(1, 300+1):\n",
        "\n",
        "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=1, verbose=0)\n",
        "    \n",
        "    model.save_weights(\"weights_bilstm.h5\")\n",
        "    \n",
        "    y_pred = model.predict(X_valid)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    acc = np.sum(y_pred==Y_valid)/len(Y_valid)\n",
        "\n",
        "    y_true = list(map(bin_label, Y_valid))\n",
        "    y_pred = list(map(bin_label, y_pred))\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    SE = tp/(tp+fn)\n",
        "    SP = tn/(fp+tn)\n",
        "\n",
        "    if SE+acc > best_SE+best_ACC:\n",
        "        best_SE, best_ACC = SE, acc\n",
        "        best_model.set_weights(model.get_weights())\n",
        "        pcnt = 0\n",
        "    else:\n",
        "        pcnt += 1\n",
        "    \n",
        "    print(\"Epoch: %d | SE: %.4f | Best SE: %.4f | ACC: %.4f | Best ACC: %.4f | AUC: %.4f | SP: %.4f\" %(e, SE, best_SE, acc, best_ACC, auc, SP))\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(62836, 47, 1)\n",
            "(15709, 47, 1)\n",
            "Epoch: 1 | SE: 0.9721 | Best SE: 0.9721 | ACC: 0.9880 | Best ACC: 0.9880 | AUC: 0.9835 | SP: 0.9949\n",
            "Epoch: 2 | SE: 0.9793 | Best SE: 0.9793 | ACC: 0.9915 | Best ACC: 0.9915 | AUC: 0.9887 | SP: 0.9980\n",
            "Epoch: 3 | SE: 0.9842 | Best SE: 0.9842 | ACC: 0.9941 | Best ACC: 0.9941 | AUC: 0.9911 | SP: 0.9980\n",
            "Epoch: 4 | SE: 0.9853 | Best SE: 0.9853 | ACC: 0.9949 | Best ACC: 0.9949 | AUC: 0.9919 | SP: 0.9985\n",
            "Epoch: 5 | SE: 0.9773 | Best SE: 0.9853 | ACC: 0.9934 | Best ACC: 0.9949 | AUC: 0.9882 | SP: 0.9992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7be2b203ca64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights_bilstm.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry4CA2BUIKwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"weights_bilstm.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDEwz9lIVUHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}